{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notes : the model should be robust for both male and female speakers , and all age groups\n",
    "\n",
    "\n",
    "\n",
    "# To do \n",
    "\n",
    "# create dataset \n",
    "# use youtube-dl to download audio, use sox to convert audio to 16k mono format \n",
    "# download robust audio samples\n",
    "\n",
    "# create tensorflow model\n",
    "\n",
    "# create json dataset file , and dataloader\n",
    "\n",
    "\n",
    "# ________________________________________________________\n",
    "\n",
    "# ideas \n",
    "\n",
    "# use MFCC, total energy and F0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '/media/saurabh/New Volume/tf_audio_sentiment/pyAudioAnalysis')\n",
    "\n",
    "from  pyAudioAnalysis  import audioBasicIO\n",
    "from  pyAudioAnalysis import audioFeatureExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n",
    "from python_speech_features import logfbank\n",
    "from tensorflow.contrib import rnn\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "directory_path='/media/saurabh/New Volume/tf_audio_sentiment/data/'\n",
    "directory = os.fsencode(directory_path)\n",
    "\n",
    "model_path = \"/media/saurabh/New Volume/tf_audio_sentiment/models/rnn_model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_to_mfcc(fileurl):\n",
    "    rate, sig = wav.read(fileurl)\n",
    "    mfcc_feat = mfcc(sig,rate)\n",
    "#d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "#fbank_feat = logfbank(sig,rate)\n",
    "\n",
    "    return mfcc_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 25\n",
    "batch_size = 1\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timesteps=2000 # max timesteps\n",
    "num_input = 13 # size of vector, at each timestep\n",
    "num_classes = 2 # happy or sad\n",
    "\n",
    "num_hidden = 110 # hidden layer num of features\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, timesteps, num_input]) \n",
    "y = tf.placeholder(tf.int32, [None]) #  Index of output , 0 = sad , 1 = happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function, that pads audio so that audio frames = max frames\n",
    "\n",
    "def pad(input):\n",
    "   # print(input.shape[0])\n",
    "     if input.shape[0] < max_frames:\n",
    "        \n",
    "        diff = max_frames - input.shape[0]\n",
    "        \n",
    "        # pad and return input\n",
    "        return np.pad(input,((0,diff),(0,0)), mode=\"constant\")\n",
    "    \n",
    "     else:\n",
    "        \n",
    "        return input\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
    "    'out': tf.Variable(tf.random_normal([2*num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def BiRNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, num_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, num_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define lstm cells with tensorflow\n",
    "    # Forward direction cell\n",
    "    lstm_fw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    # Backward direction cell\n",
    "    lstm_bw_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    try:\n",
    "        outputs, _, _ = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                              dtype=tf.float32)\n",
    "    except Exception: # Old TensorFlow version only returns outputs not states\n",
    "        outputs = rnn.static_bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
    "                                        dtype=tf.float32)\n",
    "        \n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logits = BiRNN(x, weights, biases)\n",
    "# prediction = tf.nn.softmax(logits) # use only for inference, softmax included in loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "#cost = tf.reduce_mean(-tf.reduce_sum(y_one_hot*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "cost = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=Logits)\n",
    "\n",
    "# Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Saver' op to save and restore all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boy.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-22-10c3877ca5bb>\", line 15, in <module>\n",
      "    accoustic_features=pad(audio_to_mfcc(directory_path + filename))\n",
      "  File \"<ipython-input-16-b6ccc63a812b>\", line 5, in pad\n",
      "    if input.shape[0] < max_frames:\n",
      "NameError: name 'max_frames' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1821, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/inspect.py\", line 666, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/inspect.py\", line 709, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/inspect.py\", line 678, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/inspect.py\", line 663, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/saurabh/anaconda3/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'max_frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        \n",
    "        \n",
    "         # Loop over all files\n",
    "        for file in os.listdir(directory):\n",
    "            filename = os.fsdecode(file)\n",
    "            if filename.endswith(\".wav\"): \n",
    "                 print(filename)\n",
    "                 accoustic_features=pad(audio_to_mfcc(directory_path + filename))\n",
    "                 \n",
    "                 \n",
    "                    \n",
    "                 print(accoustic_features.shape)\n",
    "                \n",
    "                 txt_file=filename.replace('.wav','.txt')\n",
    "                 with open(directory_path + txt_file, 'r') as myfile:\n",
    "                    data=myfile.read().replace('\\n', '')\n",
    "                    y_digit=int(data)\n",
    "                    print(y_digit)\n",
    "            \n",
    "                    # Fit training using single example data\n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={x: accoustic_features,\n",
    "                                                          y: [y_digit]})\n",
    "            \n",
    "                 \n",
    "                    print(c)    \n",
    "        \n",
    "                 continue\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        \n",
    "     \n",
    "            \n",
    "           \n",
    "        # Display logs per epoch step\n",
    "      #  if (epoch+1) % display_step == 0:\n",
    "       #     print (\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "\n",
    "    \n",
    "    print (\"Optimization Finished!\")\n",
    "    \n",
    "    # Save model weights to disk\n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "          \n",
    "\n",
    "    # Test model\n",
    " #   correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy for 3000 examples\n",
    "  #  accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  #  print \"Accuracy:\", accuracy.eval({x: mnist.test.images[:3000], y: mnist.test.labels[:3000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
